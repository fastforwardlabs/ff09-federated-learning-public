## The Problem and the Solution

In this chapter, we will describe three hypothetical scenarios that seem very
different, but which share characteristics that make them a great fit for
federated learning. We'll then introduce a specific federated learning
algorithm, and explain how it helps. Finally, we'll address the practical
systems problems that complicate its use.

### User Data on Smartphones

![Smartphones generate a wealth of data including, pictures, text messages and emails.](figures/ff09-03.png)

Our first scenario concerns Pear, a company that makes a popular smartphone.
Users love it. They use it to take pictures of their kids, email their
colleagues, and write quick text messages to friends. All of this activity on
millions of Pear phones generates data that, if it were combined, would allow
Pear to train models to make its phones even better.

Pear's phones could learn to spot particularly good baby photos and proactively
offer to share them with friends and family. They could make it easier to write
emails that are more likely to receive quick replies. And they could make
composing text messages even quicker and easier by accurately suggesting the
next phrase, whatever the language.

![Smartphone manufacturers could use that data to personalize a user's experience -- but they require access to do so.](figures/ff09-04.png)

The difficulty is that many users are not comfortable sharing the training data
these examples would require (baby photos, work emails, personal text messages)
with a multinational corporation. Even among those who are not sensitive to
privacy concerns, some will still refuse to share their data because they don't
want to waste their bandwidth uploading data that will primarily benefit a
private company. And among those who do choose to share their data, that data
is often protected by laws that place significant administrative burdens on
companies that wish to use it.

Pear understands these concerns, and has earned a reputation as a company that
takes privacy more seriously than its competitors. How can Pear add new
predictive features to its phones while respecting its users' privacy?

### Predictive Maintenance

TurbineCorp sells turbines for installation in power stations. These
machines are profitable to run but expensive to maintain, and very expensive to
repair. TurbineCorp wants to differentiate itself from its competitors by
offering customers access to a predictive model of turbine failure.

![Turbine sensor data could be used to train a predictive maintenance model.](figures/ff09-06.png)

This model would use readings from sensors installed on each turbine as input,
and return an estimate of its remaining useful life. A good model would reduce
the likelihood of an expensive failure by prompting the owner to maintain a turbine
before it fails. It would also help avoid the almost equally expensive mistake
of maintaining a turbine too early and too often.

This model needs training data—but testing lots of turbines until they failed in
order to acquire that data would be an expensive endeavor for TurbineCorp. It
would be less costly for TurbineCorp if its customers were to send it such data.
More importantly, the failures actual customers experience will be more
representative of real-world use than those TurbineCorp would see in factory
experiments. In short, training data acquired from customers would be both cheaper and
better.

But there are several problems. Some of their customers are reluctant to share
details about turbine failures in their facilities. Furthermore, some
operate in countries such as China, where power stations are considered
strategic assets, and are therefore legally prevented from exporting sensor
data. And, as a practical matter, the volume of data generated by the dozens of 
sensors on each turbine is enormous, which makes streaming it back to TurbineCorp 
an engineering challenge.

### Medical AI

Nephrodyne, a medical device company, wants to offer a wearable device that
detects kidney problems in users before they become acutely serious. The company knows 
from lab trials that its prototype rule-based device performs fairly well, but it
does not have the accuracy required for use by nonexperts outside a hospital.
Nephrodyne is confident that a machine learning model would perform even better
than the rule-based model, and its business team has determined that Germany would be
the best place to launch this product.

![Wearable medical devices collect data that could save lives.](figures/ff09-05.png)

The problem is, as a private company based in the United States, Nephrodyne is 
having trouble getting access to the representative training data required to 
build the model. Data protection regulations in the European Union place significant 
regulatory burdens on companies working with personal data, especially those 
outside the EU. Likewise, HIPAA regulations in the US make it difficult to work 
with US patient data (and in any case, that American patient data would differ
systematically from that of the target customers in Germany). And finally, 
anywhere in the world, but especially in Germany, patients are typically 
unwilling to share their personal data with a private medical device company.
Patients do, however, share their data with their healthcare providers.

Given these constraints, how can Nephrodyne work with multiple healthcare providers to train the
accurate model it needs to build its new product?

### The Federated Learning Setting

These three scenarios share two common characteristics. These characteristics
comprise what machine learning experts call the _setting_ of federated
learning.

![Federated learning helps when the data cannot be moved.](figures/ff09-07.png)

First, the most representative (and cheapest) training data cannot be moved
away from its source. This characteristic is the most important for identifying
a problem that might be a good fit for federated learning. The reasons for this
constraint can include privacy concerns, regulatory impediments, and practical
engineering challenges.

![Federated learning helps when the data on each node is different.](figures/ff09-08.png)

Second, each source of potential training data is different from every other.
Each of these sources will show biases relative to the overall dataset. For
example, Pear wants to predict which emails will receive replies, but perhaps
one user almost always gets a reply, and one user almost never does. Neither
user is typical. Or perhaps two of TurbineCorp’s customers stress their
turbines in different ways and observe different failure modes. And maybe one
of Nephrodyne’s users simply doesn’t have much data. The fact that any one
source’s data is biased and small relative to the total dataset means that it's
difficult to build a good global model based on data from a single source.

Here we'll introduce the term _node_, used in this report to refer to a source 
of training data. A node might be a physical device, a person, a facility
or other geographic location, a legal entity, or even a country. If each node
will not or cannot share its data directly, or if you are concerned that any
one node might produce a biased subset of data, then you have a problem that is
potentially a good fit for federated learning!

::: info

#### Distributed machine learning

Federated learning is one example of distributed machine learning, but there
exists another variety that is currently more
common and more mature: distributed machine learning in the
datacenter.^[One of the earliest uses of the term "federated learning"
draws this distinction in its title: see Jakub Konečný, Brendan McMahan, and Daniel 
Ramage's paper ["Federated
Optimization: Distributed Optimization Beyond the Datacenter."](https://arxiv.org/abs/1511.03575)] In this setting,
most of the practical constraints of federated learning go away. In particular,
we are free to move training data between nodes, and communication between them
is relatively fast and cheap. 

Algorithms for distributed machine learning in the absence of the constraints
of federated learning differ in various ways that trade off speed, complexity,
and accuracy. In most circumstances, it's best to let the tool you're using
decide these algorithmic details. The cluster computing framework Apache Spark
supports distributed machine learning out of the box and works well for many
use cases. Dask, a library for parallel computing in Python, also supports machine
learning and may be a good choice for custom use cases or experimentation. Deep
learning packages like TensorFlow and PyTorch provide distributed
implementations and can additionally be layered on management platforms like
YARN and Kubernetes^[E.g., [TonY](https://github.com/linkedin/TonY) and
[Kubeflow](https://www.kubeflow.org/).] for robustness and fault tolerance.

:::

### A Federated Learning Algorithm

So, how does federated learning work?

The crucial insight is to realize that the nodes, which are the sources of
training data, are not only data storage devices. They are also computers
capable of training a model themselves. The federated solution takes advantage
of this by training a model on each node.

The server first sends each node an instruction to train a model of a
particular type, such as a linear model, a support vector machine (SVM), or,
in the case of deep learning, a particular network architecture.

On receiving this instruction, each node trains the model on its subset of the
training data. Full training of a model would require many iterations of an
algorithm such as gradient descent, but in federated learning the nodes train
their models for only a few iterations. In that sense, each node's model is
partially trained after following the server's instruction. 

The nodes then send their partially trained models back to the server.
Crucially, they do not send their training data back.

The server combines the partially trained models to form a federated
model. One way to combine the models is to take the average of each
coefficient, weighting by the amount of training data available on the
corresponding node. This is called _federated averaging_.

The combined federated model is then transmitted back to the nodes, where it
replaces their local models and is used as the starting point for another round
of training. After several rounds, the federated model converges to a good
global model. From round to round, the nodes can acquire new training data.
Some nodes may even drop out, and others may join.

In summary, the algorithm works like this:

![A federated learning algorithm.](figures/ff09-09.png)

This algorithm makes it possible to train a model using all the training data
spread across the nodes, without moving that data off the nodes.

It is difficult (although not in general impossible) for the server to
reconstruct the training data from the trained models it receives from each
node. We will discuss this possibility in [5. Ethics](#ethics), but for now, we simply note
that the server does not have or need access to the training data. Indeed, no
training occurs on the server, so it doesn't need specialized training hardware
such as a GPU.

The amount of data the nodes have to send to the server is much less than it
would be if the training data were shared directly. This is because a machine
learning model is generally much smaller than the data on which it was trained.

### Applicability

Federated learning is more complicated than working with all the data on one
machine. If moving the data is an option, you should try that before you try
federated learning. But even if moving the data is not an option, there are a
few things you should consider before you take the leap.

#### The Data on the Nodes

Federated learning gives you access to more training data. But if that extra
training data won't help you make better predictions than the data you
already have, then federated learning will not help. For more training data to
help, two things must be true. 

First, there must be room for improvement. If the model structure lacks the
flexibility to capture the patterns in the training data, then it doesn't matter
how much training data you throw at it.^[You can check if this is true by
constructing a learning curve using the data you do have.]

Second, the additional training data must be predictive of the shared task.
This is often assumed in non-federated learning. For example, a language model
trained with the text of 1,000 English books will be better than a language
model trained with 10 English books. But the nodes in a federated model could
be so completely different or uncorrelated that the data they have to offer is
not helpful. Two nodes are unlikely to train a good language model together if
one of them uses 10 English books and the other uses 10 Japanese books. 

As a more realistic example, suppose the potential nodes of a federated network
are businesses that want to predict how many servers they will need next year.
It's quite possible that the server demands of these businesses are driven by
the same external factors, and therefore correlated. In this case federated
learning may help. But if their server demands are uncorrelated, each business
will get results that are just as good (or better), with less expense, by
building its own model using only its own data. 

#### Walk Before You Can Run

Before doing something new in machine learning, it is a best practice to
establish a well-understood performance benchmark. In the context of federated
learning, that means training a non-federated model on representative proxy
data. For example, you might first train a prototype predictive text model on a
Wikipedia corpus, or a predictive maintenance model on laboratory stress tests.

This benchmark is valuable because it gives you an idea of the performance you
can expect from a federated model before you build it. That's because, while
federated learning is almost as good as having direct access to all the
training data, it is not usually better. The non-federated model therefore
places an upper limit on the performance of a federated model trained _on the
same data_. 

The only situation in which a federated model could beat a non-federated
benchmark is if, in the move to federated learning, you gain access to more or
qualitatively better training data. This is not necessarily a rare situation, 
but relying on it is a risk you should carefully assess.

#### Not Only Deep Learning

It is possible to train any kind of machine learning model using federated
learning, provided there exists a meaningful way to combine two models. This is
true of at least linear models, SVMs, and neural networks. In particular,
despite what you may have heard, federated learning is not only applicable to
deep learning.

In our prototype we do use a neural network, but the most prominent documented
production example of federated learning (see [4.2.1 Firefox](#firefox)) uses an SVM. Each
type of model has its usual advantages and disadvantages in a federated setting
(flexibility, training data requirements, speed, etc.). Your choice may be
restricted in practice if the nodes are unusual edge hardware (see
[4.3 Tools and Vendors](#tools-and-vendors)).

### Systems Issues

An attempt to use any algorithm in the real world will face practical challenges
due to the hardware, software, and network. Computer scientists call these
_systems issues_. Sometimes they are mere details that can be addressed easily,
but sometimes they render an elegant algorithm useless in practice. It is
therefore important to be aware of them.

![Training models on client devices uses power.](figures/ff09-17.png)

In some contexts where federated learning would otherwise make sense, it can be
unsuitable because of its power demands. For example, Pear's smartphone users
may not want to dedicate a portion of their battery to training a neural
network in the background. And training isn't the only potential power sink:
communication over a cellular network using the radio antenna is a particularly
power-hungry task on a smartphone.^[Power consumption and communication
costs are closely related. See [6.1 Reducing Communications Cost](#reducing-communications-cost) for more on this topic.]
Federated learning is less demanding in this respect than a strategy that
involves transmitting _all_ the training data back to the server, but it is
more demanding than shipping a static model to the phone just once. This
trade-off may be worth making if the federated model is much better than a
static model trained once on unrealistic data, but you'll need to consider
whether this is the case.

![Some nodes may drop out of the network.](figures/ff09-11.png)

There's also the possibility that a node may drop out. The most obvious example
of this is a smartphone user who turns their phone off, but a healthcare
provider participating in Nephrodyne's network or a power station participating
in TurbineCorp's network might also choose or be forced to cease participation.
The individual nodes cannot be counted on to have the uptime you can expect
of a server in a datacenter. If federated learning is distributed across
more than a handful of nodes, you can pretty much guarantee at least _one_ of them
will become temporarily or permanently unavailable at some point. Federated 
learning must be robust to this possibility.

![Some nodes may take longer to do their share of the work.](figures/ff09-12.png)

Finally, even with plenty of power and no dropouts, the server is faced with
the unavoidable reality that some nodes are likely to be stragglers that take longer to do
their work, because they have either slow hardware or a slow network
connection. Can this risk be reduced? At what point should the server abandon
hope of receiving an update from a particular node? How should it handle an
update if it arrives after the server has already combined the updates from the
other nodes? The answers to these questions depend on the details of your
system and the particular federated learning algorithm you are using. In some
cases, they are also the subject of current research (see [6. Future](#future)).

In any production application of federated learning it is essential to consider
the real-world issues you will face and, where possible, mitigate the damage
they do. In the next chapter we describe how we built a working product using federated
learning. Our prototype avoids some of these systems issues, but is forced to
deal with others. 

::: info

#### Machine learning on the edge

In order for federated learning to be possible, the nodes must be able to
_train_ a model. The ability to do _inference_ (i.e., apply a pretrained model)
is not sufficient. Training is not always possible on edge devices such as
specialized IoT hardware. This is particularly true in the case of neural
networks. This difficulty is due to the current state of the toolchain rather
than anything fundamental, and we expect that limitation to go away in the near
future.^[See [4.3.4 Mobile And Edge](#mobile-and-edge) and ["What Does It Take
to Train Deep Learning Models
On-Device?"](https://petewarden.com/2018/10/04/what-does-it-take-to-train-deep-learning-models-on-device/)]

But even if you can't train on edge devices (and therefore can't use them for
federated learning), machine learning inference on edge devices is still a
very exciting possibility. Among the many compelling arguments for shifting the
burden of data processing (including featurization and inference) to edge
devices is _cost_. You save money because the owners of the edge devices (i.e.,
your users) provide the compute resources.

In a sense, along with the move to the cloud (and serverless in particular),
moving machine learning to edge devices is part of a general trend toward
minimizing the long-lived infrastructure of a system.^[See 
["How
We Built a Big Data Platform on AWS for 100 Users for Under $2 a Month"](https://read.acloud.guru/how-we-built-a-big-data-analytics-platform-on-aws-for-100-large-users-for-under-2-a-month-b37425b6cc4) for an
example of migration of a backend system to serverless and the "AI frontend" to
TensorFlow.js running on user devices. Together these changes resulted in a cost
reduction of 3,700x.]

:::
